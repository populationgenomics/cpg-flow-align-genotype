# Alignment and Genotyping

A [CPG-Flow](https://github.com/populationgenomics/cpg-flow) migration of the Alignment and Genotyping workflow from Production Pipelines.

Alignment: https://github.com/populationgenomics/production-pipelines/blob/ca8741c9d34c85f3f3e0811f081e67d56086d831/cpg_workflows/stages/align.py

Genotyping: https://github.com/populationgenomics/production-pipelines/blob/ca8741c9d34c85f3f3e0811f081e67d56086d831/cpg_workflows/stages/genotype.py

Cram QC: https://github.com/populationgenomics/production-pipelines/blob/main/cpg_workflows/stages/cram_qc.py

gVCF QC: https://github.com/populationgenomics/production-pipelines/blob/main/cpg_workflows/stages/gvcf_qc.py

These workflows start with the single-sample assay data we've received from our collaborators, FastQ, BAM, or FQ.ora,
and carry out the alignment and genotyping steps of the analysis, including:
- Aligning the reads to the reference genome using DRAGMAP (Dragen-OS)
- Generating alignment quality metrics using Samtools, Picard, and Somalier fingerprinting
- Genotyping the aligned reads using GATK HaplotypeCaller
- Generating gVCF quality metrics using Picard

This single-sample workflow has a dedicated entrypoint, and can be operated through analysis runner as follows:

```bash
analysis-runner --skip-repo-checkout \
    --image australia-southeast1-docker.pkg.dev/cpg-common/images/cpg-flow-align-genotype:0.3.2 \
    --config CONFIG_FILE.toml \
    --dataset seqr \
    --description 'Single-Sample data generation' \
    --access-level full \
    --output-dir OUTPUT_DIR \
    run_workflow
````

A secondary workflow continues on from the single-sample steps, and produces Dataset-level outputs, including:
- Runs Somalier Relate on the Dataset's Somalier fingerprints to generate a Dataset-level pedigree
- Uses the somalier outputs to check relationships against the expected pedigree
- Runs Dataset-level MultiQC for the CRAM and gVCF metrics, publishing an HTML report, and writing the results to Slack

This Dataset-level workflow can be run in a similar way, but with a different entrypoint:
```bash
analysis-runner --skip-repo-checkout \
    --image australia-southeast1-docker.pkg.dev/cpg-common/images/cpg-flow-align-genotype:0.3.2 \
    --config CONFIG_FILE.toml \
    --dataset seqr \
    --description 'Dataset-Level QC workflow' \
    --access-level full \
    --output-dir OUTPUT_DIR \
    dataset_workflow
````

## Configuration

A [configuration template file](src/align_genotype/config_template.toml) is provided, which contains all the settings and references required to run the workflow. This file can be copied and modified to create a specific configuration for a given run. This config file should contain all values required by the workflow, meaning there is no reliance on the default global configuration generated by `Analysis-Runner`, except for relating to storage locations.

Two entries in the config template should be modified for each run:

- `workflow.input_cohorts`:  a list of Cohort IDs to be used as input
- `workflow.sequencing_type`: 'exome' or 'genome', depending on the type of sequencing data being processed

## Structure

This repository has the following structure:

```text
src
├── align_genotype
│   ├── __init__.py
│   ├── config_template.toml
│   ├── dataset_stages.py
│   ├── dataset_workflow.py
│   ├── jobs
│   │   ├── __init__.py
│   │   ├── align.py
│   │   ├── cram_qc_samtools.py
│   │   ├── cram_qc_somalier.py
│   │   ├── cram_qc_verify.py
│   │   ├── genotype.py
│   │   ├── multiqc.py
│   │   ├── picard.py
│   │   └── somalier.py
│   ├── run_workflow.py
│   ├── scripts
│   │   ├── __init__.py
│   │   └── check_pedigree.py
│   ├── stages.py
│   └── utils.py
```
